# -*- coding: utf-8 -*-
"""Proyek Akhir : Image Classification Model Deployment(2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mae717tFVX3hZXF6NAAnmiD5fWz0LMn8

#Derie Dariant
#Proyek Akhir : Image Classification Model Deployment

###Library
"""

!pip install -q kaggle
!pip install split-folders

#install library
import os
import cv2
import shutil
import numpy as np
import tensorflow as tf
import splitfolders
import sklearn
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import pathlib
from sklearn import datasets
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from google.colab import files
from google.colab.patches import cv2_imshow

files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

"""###Dataset"""

#download dataset from kaggle
!kaggle datasets download -d tongpython/cat-and-dog
!kaggle datasets download -d phucthaiv02/butterfly-image-classification
!unzip /content/cat-and-dog.zip -d dog_cat
!unzip /content/butterfly-image-classification.zip -d butterfly

#create dataset folder
!mkdir animals
!mv '/content/butterfly/train' '/content/animals'
!mv '/content/dog_cat/training_set/training_set/cats' '/content/animals'
!mv '/content/dog_cat/training_set/training_set/dogs' '/content/animals'
os.rename ('/content/animals/train', '/content/animals/butterflies')
!ls '/content/animals'

"""###Image resolution test"""

#image resolution test 1
img1 = cv2.imread('/content/animals/butterflies/Image_10.jpg')
cv2_imshow(img1)
print (img1.shape)

#image resolution test 2
img2 = cv2.imread('/content/animals/cats/cat.100.jpg')
cv2_imshow(img2)
print (img2.shape)

#image resolution test 3
img3 = cv2.imread('/content/animals/dogs/dog.1020.jpg')
cv2_imshow(img3)
print (img3.shape)

"""###Create model"""

#Divide data into train data & validation data
base_dir= '/content/animals'
splitfolders.ratio(base_dir, output='/content/animals', seed=1337, ratio=(0.8, 0.2))
train_dir= os.path.join(base_dir,'train')
validation_dir= os.path.join(base_dir,'val')

os.listdir('/content/animals/train')

os.listdir('/content/animals/val')

train_datagen= ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    zoom_range=0.2,
    shear_range=0.2,
    fill_mode='nearest'
)

test_datagen= ImageDataGenerator(
    rescale=1./255
)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150,150),
    batch_size=128,
    class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    validation_dir,
    target_size=(150,150),
    batch_size=128,
    class_mode='categorical'
)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax'),
])
base_learning_rate = 0.0001
model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])
model.summary()

#membuat Callback
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.92 and logs.get('val_accuracy')>0.92):
      print("\n Akurasi telah mencapai 92%)")
      self.model.stop_training = True

callbacks = myCallback()

"""###Output model"""

history = model.fit(
      train_generator,
      steps_per_epoch=75,
      epochs=50,
      validation_data=validation_generator,
      validation_steps=5,
      verbose=2, batch_size=1200,  callbacks=[callbacks])

#plot loss
plt.plot(history.history['loss'], color = 'blue')
plt.plot(history.history['val_loss'], color = 'red')
plt.title('LOSS')
plt.legend(['train','validation'], loc='upper right')
plt.show()

#plot accuracy
plt.plot(history.history['accuracy'], color = 'blue')
plt.plot(history.history['val_accuracy'], color = 'red')
plt.title('ACCURACY')
plt.legend(['train', 'validation'], loc= 'upper left')
plt.show()

"""###Model prediction test"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
upload = files.upload()

for fn in upload.keys():

  #predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classes = model.predict(images, batch_size=64)

  if classes [0,0]!=0:
    print ('Butterfly')

  elif classes [0,1]!=0:
    print ('Cat')
  else:
    print ('Dog')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
upload = files.upload()

for fn in upload.keys():

  #predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classes = model.predict(images, batch_size=64)

  if classes [0,0]!=0:
    print ('Butterfly')

  elif classes [0,1]!=0:
    print ('Cat')
  else:
    print ('Dog')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
upload = files.upload()

for fn in upload.keys():

  #predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classes = model.predict(images, batch_size=64)

  if classes [0,0]!=0:
    print ('Butterfly')
  elif classes [0,1]!=0:
    print ('Dog')
  else:
    print ('Cat')

"""###Saving model to the tf-lite"""

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('vegs_tflite')
tflite_model_file.write_bytes(tflite_model)

